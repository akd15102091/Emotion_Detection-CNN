{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 100\n",
    "CLASS = [\"angry\",\"disgust\",\"fear\",\"happy\",\"neutral\",\"sad\",\"surprise\"]\n",
    "train_dir = \"images/train\"\n",
    "test_dir = \"images/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(dir_name) :\n",
    "    \n",
    "    for cl in CLASS :\n",
    "        cl_path = os.path.join(dir_name,cl)\n",
    "        class_num = CLASS.index(cl)\n",
    "        for img in os.listdir(cl_path) :\n",
    "            try :\n",
    "                img_array = cv2.imread(os.path.join(cl_path,img))\n",
    "                img_array = cv2.resize(img_array,(IMAGE_SIZE,IMAGE_SIZE))\n",
    "                gray_img  = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
    "                training_data.append([gray_img, class_num])\n",
    "            except :\n",
    "                pass\n",
    "            \n",
    "        random.shuffle(training_data)\n",
    "        \n",
    "    #return data_set\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_data(train_dir)\n",
    "create_data(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35887\n"
     ]
    }
   ],
   "source": [
    "#shuffle the data\n",
    "random.shuffle(training_data)\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "y = np.array(y)\n",
    "\n",
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(os.listdir(train_dir))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class labels to one-hot encoding\n",
    "y = np_utils.to_categorical(y, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp) :\n",
    "    model = keras.Sequential([\n",
    "                                Conv2D(\n",
    "                                    filters = hp.Int('conv_1_filter', min_value=32,max_value=190, step=32),\n",
    "                                    kernel_size=hp.Choice('conv_1_kernel',values=[3,5]),\n",
    "                                    activation='relu',input_shape=(100,100,1)\n",
    "                                ),\n",
    "                                MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "        \n",
    "                                Conv2D(\n",
    "                                    filters = hp.Int('conv_2_filter', min_value=64, max_value=256, step=32),\n",
    "                                    kernel_size=hp.Choice('conv_2_kernel',values=[3,5]),\n",
    "                                    activation='relu'\n",
    "                                ),\n",
    "                                MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "        \n",
    "                                Conv2D(\n",
    "                                    filters = hp.Int('conv_3_filter', min_value=48, max_value=240, step=32),\n",
    "                                    kernel_size=hp.Choice('conv_3_kernel',values=[3,5]),\n",
    "                                    activation='relu'\n",
    "                                ),\n",
    "                                MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "        \n",
    "                                keras.layers.Flatten(),\n",
    "                                Dense(units=hp.Int('dense1_units', min_value=48, max_value=240, step=48), activation='relu'),\n",
    "                                Dense(units=hp.Int('dense2_units', min_value=48, max_value=240, step=48), activation='relu'),\n",
    "        \n",
    "                                Dense(num_classes,activation='softmax')\n",
    "                            ])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice(\"learning_rate\",values=[1e-2,1e-3])),\n",
    "                    loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project output/emotion_detection/oracle.json\n"
     ]
    }
   ],
   "source": [
    "tuner_Search = RandomSearch(build_model, \n",
    "                            objective=\"val_accuracy\", max_trials=4, \n",
    "                            directory=\"output\", project_name=\"emotion_detection\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 32m 48s]\n",
      "val_accuracy: 0.2581498920917511\n",
      "\n",
      "Best val_accuracy So Far: 0.5100306272506714\n",
      "Total elapsed time: 01h 55m 03s\n",
      "\n",
      "Search: Running Trial #4\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "conv_1_filter     |160               |96                \n",
      "conv_1_kernel     |3                 |3                 \n",
      "conv_2_filter     |192               |96                \n",
      "conv_2_kernel     |3                 |3                 \n",
      "conv_3_filter     |144               |208               \n",
      "conv_3_kernel     |3                 |3                 \n",
      "dense1_units      |48                |96                \n",
      "dense2_units      |192               |240               \n",
      "learning_rate     |0.01              |0.001             \n",
      "\n",
      "Epoch 1/3\n",
      "898/898 [==============================] - 1553s 2s/step - loss: 2.7905 - accuracy: 0.2397 - val_loss: 1.8087 - val_accuracy: 0.2581\n",
      "Epoch 2/3\n",
      "898/898 [==============================] - 1552s 2s/step - loss: 1.8125 - accuracy: 0.2497 - val_loss: 1.8066 - val_accuracy: 0.2581\n",
      "Epoch 3/3\n",
      "616/898 [===================>..........] - ETA: 7:51 - loss: 1.8137 - accuracy: 0.2495"
     ]
    }
   ],
   "source": [
    "tuner_Search.search(X,y, epochs=3, validation_split=0.2,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
